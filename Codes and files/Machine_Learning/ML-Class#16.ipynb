{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sonar.all-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "202  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "203  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "204  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "205  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "206  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "     0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "0    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4    0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "202  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "203  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "204  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "205  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "206  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "     0.0090  0.0032  R  \n",
       "0    0.0052  0.0044  R  \n",
       "1    0.0095  0.0078  R  \n",
       "2    0.0040  0.0117  R  \n",
       "3    0.0107  0.0094  R  \n",
       "4    0.0051  0.0062  R  \n",
       "..      ...     ... ..  \n",
       "202  0.0193  0.0157  M  \n",
       "203  0.0062  0.0067  M  \n",
       "204  0.0077  0.0031  M  \n",
       "205  0.0036  0.0048  M  \n",
       "206  0.0061  0.0115  M  \n",
       "\n",
       "[207 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0200    float64\n",
       "0.0371    float64\n",
       "0.0428    float64\n",
       "0.0207    float64\n",
       "0.0954    float64\n",
       "0.0986    float64\n",
       "0.1539    float64\n",
       "0.1601    float64\n",
       "0.3109    float64\n",
       "0.2111    float64\n",
       "0.1609    float64\n",
       "0.1582    float64\n",
       "0.2238    float64\n",
       "0.0645    float64\n",
       "0.0660    float64\n",
       "0.2273    float64\n",
       "0.3100    float64\n",
       "0.2999    float64\n",
       "0.5078    float64\n",
       "0.4797    float64\n",
       "0.5783    float64\n",
       "0.5071    float64\n",
       "0.4328    float64\n",
       "0.5550    float64\n",
       "0.6711    float64\n",
       "0.6415    float64\n",
       "0.7104    float64\n",
       "0.8080    float64\n",
       "0.6791    float64\n",
       "0.3857    float64\n",
       "0.1307    float64\n",
       "0.2604    float64\n",
       "0.5121    float64\n",
       "0.7547    float64\n",
       "0.8537    float64\n",
       "0.8507    float64\n",
       "0.6692    float64\n",
       "0.6097    float64\n",
       "0.4943    float64\n",
       "0.2744    float64\n",
       "0.0510    float64\n",
       "0.2834    float64\n",
       "0.2825    float64\n",
       "0.4256    float64\n",
       "0.2641    float64\n",
       "0.1386    float64\n",
       "0.1051    float64\n",
       "0.1343    float64\n",
       "0.0383    float64\n",
       "0.0324    float64\n",
       "0.0232    float64\n",
       "0.0027    float64\n",
       "0.0065    float64\n",
       "0.0159    float64\n",
       "0.0072    float64\n",
       "0.0167    float64\n",
       "0.0180    float64\n",
       "0.0084    float64\n",
       "0.0090    float64\n",
       "0.0032    float64\n",
       "R          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',500)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "M    111\n",
       "R     96\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('R').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35     R\n",
       "109    M\n",
       "96     M\n",
       "197    M\n",
       "21     R\n",
       "99     M\n",
       "162    M\n",
       "161    M\n",
       "123    M\n",
       "186    M\n",
       "18     R\n",
       "54     R\n",
       "163    M\n",
       "80     R\n",
       "83     R\n",
       "68     R\n",
       "129    M\n",
       "61     R\n",
       "62     R\n",
       "172    M\n",
       "145    M\n",
       "142    M\n",
       "198    M\n",
       "23     R\n",
       "36     R\n",
       "203    M\n",
       "27     R\n",
       "95     R\n",
       "187    M\n",
       "13     R\n",
       "1      R\n",
       "3      R\n",
       "147    M\n",
       "121    M\n",
       "130    M\n",
       "116    M\n",
       "182    M\n",
       "2      R\n",
       "7      R\n",
       "188    M\n",
       "125    M\n",
       "169    M\n",
       "Name: R, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score is: 76.19047619047619\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train,y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)*100\n",
    "print(f\"Decision Tree accuracy score is: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy score is: 78.57142857142857\n"
     ]
    }
   ],
   "source": [
    "RT = RandomForestClassifier()\n",
    "RT.fit(X_train, y_train)\n",
    "y_pred = RT.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)*100\n",
    "print(f\"Random Forest accuracy score is: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append((\"DT\",DecisionTreeClassifier()))\n",
    "models.append((\"RT\", RandomForestClassifier()))\n",
    "models.append((\"KNN\", KNeighborsClassifier()))\n",
    "models.append((\"LR\", LogisticRegression()))\n",
    "models.append((\"GNB\", GaussianNB()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DT', DecisionTreeClassifier()),\n",
       " ('RT', RandomForestClassifier()),\n",
       " ('KNN', KNeighborsClassifier()),\n",
       " ('LR', LogisticRegression()),\n",
       " ('GNB', GaussianNB())]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.04761904761905]\n",
      "[69.04761904761905, 76.19047619047619]\n",
      "[69.04761904761905, 76.19047619047619, 85.71428571428571]\n",
      "[69.04761904761905, 76.19047619047619, 85.71428571428571, 71.42857142857143]\n",
      "[69.04761904761905, 76.19047619047619, 85.71428571428571, 71.42857142857143, 57.14285714285714]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    obj = model\n",
    "    names.append(name)\n",
    "    obj.fit(X_train,y_train)\n",
    "    y_pred = obj.predict(X_test)\n",
    "    results.append(accuracy_score(y_test,y_pred)*100)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1857fd27e80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(names,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp310-cp310-win_amd64.whl (444.1 MB)Note: you may need to restart the kernel to use updated packages.\n",
      "     ------------------------------------ 444.1/444.1 MB 639.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "\n",
      "  Downloading grpcio-1.46.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 853.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers<2,>=1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     -------------------------------------- 57.5/57.5 KB 761.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     -------------------------------------- 65.5/65.5 KB 708.3 kB/s eta 0:00:00\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "     ---------------------------------------- 5.8/5.8 MB 324.3 kB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 364.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 667.5 kB/s eta 0:00:00\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     -------------------------------------- 42.6/42.6 KB 108.9 kB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "     ------------------------------------ 438.7/438.7 KB 623.6 kB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     -------------------------------------- 14.2/14.2 MB 824.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 699.8 kB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.22.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "     ------------------------------------ 123.7/123.7 KB 804.4 kB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 KB 1.0 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "     ------------------------------------ 156.7/156.7 KB 446.5 kB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "     -------------------------------------- 97.8/97.8 KB 557.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow) (3.0.6)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ------------------------------------ 155.3/155.3 KB 923.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anonymous\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     -------------------------------------- 77.1/77.1 KB 613.8 kB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     ------------------------------------ 151.5/151.5 KB 648.1 kB/s eta 0:00:00\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, wheel, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, opt-einsum, oauthlib, markdown, keras-preprocessing, h5py, grpcio, google-pasta, gast, absl-py, requests-oauthlib, google-auth, astunparse, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Running setup.py install for termcolor: started\n",
      "  Running setup.py install for termcolor: finished with status 'done'\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.7.0\n",
      "    Uninstalling keras-2.7.0:\n",
      "      Successfully uninstalled keras-2.7.0\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.3 h5py-3.7.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 wheel-0.37.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['R'].replace(to_replace=['R','M'],value=[0,1],inplace=True)\n",
    "X = df.iloc[:,:-1]\n",
    "y= df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000018509D93580>>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model = Sequential([\n",
    "    Dense(24,input_dim=60,activation='relu'),\n",
    "    Dense(12,  activation='relu'),\n",
    "    Dense(8,activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "ann_model.compile(\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "ann_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6967 - accuracy: 0.5212\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5273\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.6424\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7152\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.7152\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.7091\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.7212\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7455\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7818\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.8061\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.7939\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.8061\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.8242\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.8121\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.8182\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18509e27160>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(X_train,y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6905\n"
     ]
    }
   ],
   "source": [
    "loss,acc = ann_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6191012263298035\n",
      "0.6904761791229248\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(acc)\n",
    "names.append(\"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.04761904761905, 76.19047619047619, 85.71428571428571, 71.42857142857143, 57.14285714285714, 69.04761791229248]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1850b2306a0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(names,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6b60314006e06bb37448a834655c63e19de8e1b3633d56c4ceb6ed81a62438e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
